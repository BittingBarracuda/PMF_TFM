{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import chunked, ichunked\n",
    "from pmf import ProbabilisticMatrixFactorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combined_data_1.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t24058263 total lines processed.\n",
      "Processing combined_data_2.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t25000000 lines processed...\n",
      "\t26982302 total lines processed.\n",
      "Processing combined_data_3.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t22605786 total lines processed.\n",
      "Processing combined_data_4.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t25000000 lines processed...\n",
      "\t26851926 total lines processed.\n"
     ]
    }
   ],
   "source": [
    "file_name = '../archive/combined_data'\n",
    "movies = []\n",
    "user_ratings = {}\n",
    "current_movie = None\n",
    "\n",
    "for i in range(1, 5):\n",
    "    with open(f'{file_name}_{i}.txt', 'r') as current_file:\n",
    "        print(f'Processing combined_data_{i}.txt...')\n",
    "        j = 0\n",
    "        for line in current_file.readlines():\n",
    "            elems = line.split(',')\n",
    "            j += 1\n",
    "            if j % 5_000_000 == 0:\n",
    "                print(f'\\t{j} lines processed...')\n",
    "            if len(elems) == 1:\n",
    "                movie = elems[0].strip(':\\n')\n",
    "                movies.append(movie)\n",
    "                current_movie = movie\n",
    "            elif len(elems) == 3:\n",
    "                user_id, user_rating = elems[0], int(elems[1])\n",
    "                ratings = user_ratings.get(user_id, {})\n",
    "                ratings[current_movie] = user_rating\n",
    "                user_ratings[user_id] = ratings\n",
    "        print(f'\\t{j} total lines processed.')\n",
    "#print(movies)\n",
    "#print(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total users: 480189\n"
     ]
    }
   ],
   "source": [
    "N = len(list(user_ratings.keys()))\n",
    "print(f'Number of total users: {N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number 1 -> 5000 users\n",
      "\t2500 users processed...\n",
      "\t5000 users processed...\n",
      "Fitting new values with PMF model...\n",
      "\tEpoch-1...\n",
      "\tEpoch-2...\n",
      "\tEpoch-3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\pmf.py:72: RuntimeWarning: overflow encountered in multiply\n",
      "  aux_2 = aux_1 * self.U.T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch-4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\pmf.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  aux_1 = I_ij * (self.R[i, :] - np.dot(self.U[i, :], self.V))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch-5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\netflix_dataset.ipynb Celda 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kmart/Desktop/Apuntes/MasterPython/TFM/PMF_TFM/netflix_dataset.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pmf \u001b[39m=\u001b[39m ProbabilisticMatrixFactorization(D\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, sigma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, sigma_u\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, sigma_v\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kmart/Desktop/Apuntes/MasterPython/TFM/PMF_TFM/netflix_dataset.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFitting new values with PMF model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kmart/Desktop/Apuntes/MasterPython/TFM/PMF_TFM/netflix_dataset.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m pmf\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49marray(data))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kmart/Desktop/Apuntes/MasterPython/TFM/PMF_TFM/netflix_dataset.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m processed!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kmart/Desktop/Apuntes/MasterPython/TFM/PMF_TFM/netflix_dataset.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m j \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\pmf.py:23\u001b[0m, in \u001b[0;36mProbabilisticMatrixFactorization.fit\u001b[1;34m(self, R)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mM \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR\u001b[39m.\u001b[39mshape\n\u001b[0;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_initial_estimation()\n\u001b[1;32m---> 23\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__gradient_descent()\n\u001b[0;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV)\n\u001b[0;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__min_max_scaling()\n",
      "File \u001b[1;32mc:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\pmf.py:41\u001b[0m, in \u001b[0;36mProbabilisticMatrixFactorization.__gradient_descent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m     aux_U[i, :] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[i, :] \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_U_gradient(i)\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mM):\n\u001b[1;32m---> 41\u001b[0m     aux_V[:, j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV[:, j] \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_V_gradient(j)  \n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mEpoch-\u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV \u001b[39m=\u001b[39m aux_U, aux_V\n",
      "File \u001b[1;32mc:\\Users\\kmart\\Desktop\\Apuntes\\MasterPython\\TFM\\PMF_TFM\\pmf.py:73\u001b[0m, in \u001b[0;36mProbabilisticMatrixFactorization.__get_V_gradient\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m     71\u001b[0m aux_1 \u001b[39m=\u001b[39m I_ij \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR[:, j] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV[:, j]))\n\u001b[0;32m     72\u001b[0m aux_2 \u001b[39m=\u001b[39m aux_1 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU\u001b[39m.\u001b[39mT\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49msum(aux_2, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV[:, j] \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma_v)\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 5_000\n",
    "j = 1\n",
    "for chunk in chunked(user_ratings.keys(), batch_size):\n",
    "    print(f'Processing batch number {j} -> {len(chunk)} users')\n",
    "    data = []\n",
    "    for i, key in enumerate(chunk):\n",
    "        data.append([])\n",
    "        for movie in movies:\n",
    "            if movie in user_ratings[key].keys():\n",
    "                data[-1].append(user_ratings[key][movie])\n",
    "            else:\n",
    "                data[-1].append(0)\n",
    "        if (i+1) % 2_500 == 0:\n",
    "            print(f'\\t{i+1} users processed...')\n",
    "    pmf = ProbabilisticMatrixFactorization(D=10, sigma=0.1, sigma_u=0.1, sigma_v=0.1, max_epochs=10)\n",
    "    print(f'Fitting new values with PMF model...')\n",
    "    pmf.fit(np.array(data))\n",
    "    print(f'Batch {j} processed!')\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.array([[user_ratings[key][movie] if movie in user_ratings[key].keys() else 0 for movie in movies] for key in user_ratings.keys()], dtype=np.int16)\n",
    "# data = []\n",
    "# for i, key in enumerate(user_ratings.keys()):\n",
    "#     data.append([])\n",
    "#     for movie in movies:\n",
    "#         if movie in user_ratings[key].keys():\n",
    "#             data[-1].append(user_ratings[key][movie])\n",
    "#         else:\n",
    "#             data[-1].append(0)\n",
    "#     if (i+1) % 10_000 == 0:\n",
    "#         print(f'{i} users processed...')\n",
    "\n",
    "# data = np.array(data)\n",
    "# df = pd.DataFrame(data=data, index=list(user_ratings.keys()), columns=movies)\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
