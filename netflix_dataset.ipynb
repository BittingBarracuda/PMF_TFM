{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import chunked\n",
    "from pmf import ProbabilisticMatrixFactorization\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combined_data_1.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t24058263 total lines processed.\n",
      "Processing combined_data_2.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t25000000 lines processed...\n",
      "\t26982302 total lines processed.\n",
      "Processing combined_data_3.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t22605786 total lines processed.\n",
      "Processing combined_data_4.txt...\n",
      "\t5000000 lines processed...\n",
      "\t10000000 lines processed...\n",
      "\t15000000 lines processed...\n",
      "\t20000000 lines processed...\n",
      "\t25000000 lines processed...\n",
      "\t26851926 total lines processed.\n"
     ]
    }
   ],
   "source": [
    "file_name = '../archive/combined_data'\n",
    "movies = []\n",
    "user_ratings = {}\n",
    "current_movie = None\n",
    "\n",
    "for i in range(1, 5):\n",
    "    with open(f'{file_name}_{i}.txt', 'r') as current_file:\n",
    "        print(f'Processing combined_data_{i}.txt...')\n",
    "        j = 0\n",
    "        for line in current_file.readlines():\n",
    "            elems = line.split(',')\n",
    "            j += 1\n",
    "            if j % 5_000_000 == 0:\n",
    "                print(f'\\t{j} lines processed...')\n",
    "            if len(elems) == 1:\n",
    "                movie = elems[0].strip(':\\n')\n",
    "                movies.append(movie)\n",
    "                current_movie = movie\n",
    "            elif len(elems) == 3:\n",
    "                user_id, user_rating = elems[0], int(elems[1])\n",
    "                ratings = user_ratings.get(user_id, {})\n",
    "                ratings[current_movie] = user_rating\n",
    "                user_ratings[user_id] = ratings\n",
    "        print(f'\\t{j} total lines processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total users: 480189\n"
     ]
    }
   ],
   "source": [
    "N = len(list(user_ratings.keys()))\n",
    "print(f'Number of total users: {N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in test dataset 462858\n"
     ]
    }
   ],
   "source": [
    "test_file_name = '../archive/probe.txt'\n",
    "test_movies = {}\n",
    "current_movie = None\n",
    "\n",
    "with open(test_file_name, 'r') as test_file:\n",
    "    for line in test_file.readlines():\n",
    "        if line.endswith(':\\n'):\n",
    "            test_movies[line.strip(':\\n')] = []\n",
    "            current_movie = line.strip(':\\n')\n",
    "        else:\n",
    "            user_list = test_movies.get(current_movie)\n",
    "            user_list.append(line.strip('\\n'))\n",
    "            test_movies[current_movie] = user_list\n",
    "\n",
    "test_users = list(set([elem for sublist in list(test_movies.values()) for elem in sublist]))\n",
    "print(f'Number of users in test dataset {len(test_users)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch of 50000 users...\n",
      "\t10000 users processed...\n",
      "\t20000 users processed...\n",
      "\t30000 users processed...\n",
      "\t40000 users processed...\n",
      "\t50000 users processed...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50_000\n",
    "#remaining_users = batch_size - len(test_users)\n",
    "training_users = sample(test_users, batch_size)\n",
    "\n",
    "data = []\n",
    "print(f'Processing batch of {batch_size} users...')\n",
    "for i, user in enumerate(training_users):\n",
    "    data.append([])\n",
    "    for movie in movies:\n",
    "        if movie in user_ratings[user].keys():\n",
    "            data[-1].append(user_ratings[user][movie])\n",
    "        else:\n",
    "            data[-1].append(0)\n",
    "    if (i+1) % 10_000 == 0:\n",
    "        print(f'\\t{i+1} users processed...')\n",
    "\n",
    "data = np.array(data, dtype=np.int16)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 17770)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100_000\n",
    "# j = 1\n",
    "# for chunk in chunked(user_ratings.keys(), batch_size):\n",
    "#     print(f'Processing batch number {j} -> {len(chunk)} users')\n",
    "#     data = []\n",
    "#     for i, key in enumerate(chunk):\n",
    "#         data.append([])\n",
    "#         for movie in movies:\n",
    "#             if movie in user_ratings[key].keys():\n",
    "#                 data[-1].append(user_ratings[key][movie])\n",
    "#             else:\n",
    "#                 data[-1].append(0)\n",
    "#         if (i+1) % 10_000 == 0:\n",
    "#             print(f'\\t{i+1} users processed...')\n",
    "#     pmf = ProbabilisticMatrixFactorization(D=10, sigma=0.1, sigma_u=0.1, sigma_v=0.1, max_epochs=10)\n",
    "#     print(f'Fitting new values with PMF model...')\n",
    "#     pmf.fit(np.array(data))\n",
    "#     print(f'Batch {j} processed!')\n",
    "#     j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
